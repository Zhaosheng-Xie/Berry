---
title: "Class_19: PCA - Principal Components Analysis"
author: "MA615"
date: "2020-October-16"
output:
  revealjs::revealjs_presentation:
    theme: solarized
    highlight: pygments
    template: hw_temp_1.html
    css: reveal.css
    center: false
    transition: slide
---


```{r setup, include=FALSE}
library(knitr)
library(kableExtra)
library(png)
library(tidyverse)
library(grid)
library(gridExtra) 
opts_chunk$set(echo = FALSE)
```



## Why PCA in EDA?

PCA provides a way to explore the semantics of the dataset.

Reduce the dimensionality.  

Explain (most of) the variability using fewer variables and avoid multicollinearity.




-----

<h3>Aquire and prepare the data</h3>

Data:
Arrests per 100,000 for assault, murder, rape is each US state (50 States total)
Percentage of state population living in urban areas



```{r}

data("USArrests")


kable(USArrests[1:25,]) %>% kable_styling(font_size = 12)

```


-----

<h3>Center and Scale the Data</h3>

The variability in the raw data appears to show that there is more variance in assault than in urban population.  Actually, they are on differenct scales. The crime data is incidents per 100,000 in population.  Urban population is percentage of the population.
Center and normalize the variables with the scale() function. 

The results of your PCA will reflect the relative magnitude of the variables.


```{r}
kable(map_dfr(USArrests, var))

scaled = map_dfr(USArrests, scale)

kable(scaled) %>% kable_styling(font_size=12)

```



The basic idea is to capture the variability in the dataset in the least number of variables.

The reason it works is that the variace in the data is propo
proportionate to the eigen values for the variables.

The new variables are calculated using the corresponding eigen vectors

For a dataset $X_1, X_2, \dots, X_p$

The first principle component is $Z = \phi_{11} X_1 + \phi_{21}X_2 + \dots + phi_{p1}X_p$  Where the $\phi_{1p}$ weights are the elements of the first eigen vector.




```{r}
arrests.cov <- cov(scaled)

arrests.eigen <- eigen(arrests.cov)

phi <- arrests.eigen$vectors[,1:2]



t(arrests.eigen$vectors[,1]) %*% arrests.eigen$vectors[,2]

t(arrests.eigen$vectors[,2]) %*% arrests.eigen$vectors[,4]




```

-----

```{r}


phi <- -phi
row.names(phi) <- c("Murder", "Assault", "UrbanPop", "Rape")
colnames(phi) <- c("PC1", "PC2")
phi


PC1 <- as.matrix(scaled) %*% phi[,1]
PC2 <- as.matrix(scaled) %*% phi[,2]

```

-----


```{r}
PC <- data.frame(State = row.names(USArrests), PC1, PC2)
head(PC)

ggplot(PC, aes(PC1, PC2)) + 
  modelr::geom_ref_line(h = 0) +
  modelr::geom_ref_line(v = 0) +
  geom_text(aes(label = State), size = 3) +
  xlab("First Principal Component") + 
  ylab("Second Principal Component") + 
  ggtitle("First Two Principal Components of USArrests Data")


```

-----


```{r}

PVE <- arrests.eigen$values / sum(arrests.eigen$values)
round(PVE, 2)


# PVE (aka scree) plot
PVEplot <- qplot(c(1:4), PVE) + 
  geom_line() + 
  xlab("Principal Component") + 
  ylab("PVE") +
  ggtitle("Scree Plot") +
  ylim(0, 1)

# Cumulative PVE plot
cumPVE <- qplot(c(1:4), cumsum(PVE)) + 
  geom_line() + 
  xlab("Principal Component") + 
  ylab(NULL) + 
  ggtitle("Cumulative Scree Plot") +
  ylim(0,1)

grid.arrange(PVEplot, cumPVE, ncol = 2)


```



# Built-in 

The built-in PCA functions in R make all of this much easier
Start with the means and standard deviations of the scaled data

```{r}

pca_result <- prcomp(USArrests, scale = TRUE)
names(pca_result)

# means
kable(t(pca_result$center))
##   Murder  Assault UrbanPop     Rape 
##    7.788  170.760   65.540   21.232

# standard deviations
kable(t(pca_result$scale))
##    Murder   Assault  UrbanPop      Rape 
##  4.355510 83.337661 14.474763  9.366385

```
-----
The rotation matrix contains the principle component loadings

```{r}
kable(pca_result$rotation)

pca_result$rotation <- -pca_result$rotation
kable(pca_result$rotation)

```

-----
R calculates eigenvectors that point in the negative direction.
Lets fix that


```{r}

pca_result$x <- - pca_result$x
kable(pca_result$x[1:20,])

```
-----

The biplot of the first two components. The scale=0 argument produces arros that are scale as the loadings.


```{r}
biplot(pca_result, scale = 0)

```

-----
The proportion of variance explained by each principle component is the variance
explained by each principal component deviced by the total variance explained by all
four principal components

```{r}

kable(pca_result$sdev)

VE <- pca_result$sdev^2

kable(VE)


PVE <- VE / sum(VE)

kable(round(PVE, 2))
```


























